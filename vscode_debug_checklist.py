# -*- coding: utf-8 -*-
"""
VS Code è°ƒè¯•å™¨ä½¿ç”¨æ£€æŸ¥æ¸…å•
åœ¨è°ƒè¯•æ—¶å¯ä»¥å‚è€ƒè¿™ä¸ªæ–‡ä»¶
"""

"""
==========================================
ğŸ¯ æ–­ç‚¹è®¾ç½®æ£€æŸ¥æ¸…å•
==========================================
"""

# âœ… å¿…è®¾æ–­ç‚¹ï¼ˆåœ¨ train.pyï¼‰:
æ–­ç‚¹ä½ç½® = {
    "ç¬¬115è¡Œ": "æŸ¥çœ‹GPUæ•°æ® - x, labels, edge_index",
    "ç¬¬125è¡Œ": "æŸ¥çœ‹æ¨¡å‹è¾“å‡º - out",
    "ç¬¬126è¡Œ": "æŸ¥çœ‹æŸå¤±å€¼ - loss",
    "ç¬¬134è¡Œ": "æŸ¥çœ‹æ¢¯åº¦ - loss.backward() ä¹‹å"
}

# ğŸ“ å¯é€‰æ–­ç‚¹ï¼ˆåœ¨ models/GDN.pyï¼‰:
æ¨¡å‹å†…éƒ¨æ–­ç‚¹ = {
    "ç¬¬171è¡Œå¼€å§‹": "GDN.forward() æ–¹æ³•å…¥å£",
    "æŸ¥çœ‹embedding": "èŠ‚ç‚¹åµŒå…¥å­¦ä¹ è¿‡ç¨‹",
    "æŸ¥çœ‹graphæ„å»º": "åŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„TopKå›¾æ„å»º"
}


"""
==========================================
ğŸ” è°ƒè¯•æ§åˆ¶å°å¸¸ç”¨å‘½ä»¤
==========================================
"""

# åœ¨æ–­ç‚¹æš‚åœæ—¶ï¼Œåœ¨è°ƒè¯•æ§åˆ¶å°è¾“å…¥è¿™äº›å‘½ä»¤ï¼š

# === æŸ¥çœ‹Shape ===
x.shape              # è¾“å…¥å½¢çŠ¶
out.shape            # è¾“å‡ºå½¢çŠ¶
labels.shape         # æ ‡ç­¾å½¢çŠ¶
edge_index.shape     # è¾¹ç´¢å¼•å½¢çŠ¶

# === æŸ¥çœ‹æ•°å€¼èŒƒå›´ ===
x.min(), x.max()
out.min(), out.max()
labels.min(), labels.max()

# === æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯ ===
x.mean()             # å‡å€¼
x.std()              # æ ‡å‡†å·®
loss.item()          # æŸå¤±å€¼

# === æŸ¥çœ‹è®¾å¤‡ ===
x.device             # åº”è¯¥æ˜¯ cuda:0 æˆ– cpu
model.device         # æ¨¡å‹æ‰€åœ¨è®¾å¤‡

# === æŸ¥çœ‹å…·ä½“æ•°å€¼ ===
x[0]                 # ç¬¬ä¸€ä¸ªæ ·æœ¬
x[0, 0, :]           # ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼Œç¬¬ä¸€ä¸ªä¼ æ„Ÿå™¨ï¼Œæ‰€æœ‰æ—¶é—´æ­¥
out[0, :5]           # ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼Œå‰5ä¸ªä¼ æ„Ÿå™¨çš„é¢„æµ‹å€¼
labels[0, :5]        # ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼Œå‰5ä¸ªä¼ æ„Ÿå™¨çš„çœŸå®å€¼

# === è®¡ç®—è¯¯å·® ===
(out - labels).abs().mean()         # å¹³å‡ç»å¯¹è¯¯å·®
((out - labels) ** 2).mean()        # å‡æ–¹è¯¯å·®
(out - labels).abs().mean(dim=0)    # æ¯ä¸ªä¼ æ„Ÿå™¨çš„å¹³å‡è¯¯å·®

# === æ£€æŸ¥å¼‚å¸¸å€¼ ===
torch.isnan(x).any()      # æ˜¯å¦æœ‰NaN
torch.isinf(x).any()      # æ˜¯å¦æœ‰Inf
torch.isnan(out).any()
torch.isnan(loss)

# === æŸ¥çœ‹æ¢¯åº¦ï¼ˆåœ¨loss.backward()ä¹‹åï¼‰===
list(model.parameters())[0].grad              # ç¬¬ä¸€å±‚å‚æ•°çš„æ¢¯åº¦
list(model.parameters())[0].grad.mean()       # æ¢¯åº¦å‡å€¼
list(model.parameters())[0].grad.max()        # æ¢¯åº¦æœ€å¤§å€¼


"""
==========================================
ğŸ“Š ç›‘è§†è¡¨è¾¾å¼å»ºè®®
==========================================
åœ¨ VS Code çš„"ç›‘è§†"é¢æ¿ä¸­æ·»åŠ è¿™äº›è¡¨è¾¾å¼ï¼Œ
å®ƒä»¬ä¼šå®æ—¶æ›´æ–°ï¼š
"""

ç›‘è§†è¡¨è¾¾å¼åˆ—è¡¨ = [
    "i_epoch",                    # å½“å‰epoch
    "batch_idx",                  # å½“å‰batch
    "x.shape",                    # è¾“å…¥shape
    "out.shape",                  # è¾“å‡ºshape
    "loss.item()",                # æŸå¤±å€¼
    "x.mean().item()",            # è¾“å…¥å‡å€¼
    "out.mean().item()",          # è¾“å‡ºå‡å€¼
    "(out - labels).abs().mean().item()",  # å¹³å‡ç»å¯¹è¯¯å·®
]


"""
==========================================
ğŸ¬ å®Œæ•´è°ƒè¯•æµç¨‹ç¤ºä¾‹
==========================================
"""

è°ƒè¯•æµç¨‹ = """
1. åœ¨ train.py ç¬¬125è¡Œè®¾ç½®æ–­ç‚¹ï¼ˆout = model()ï¼‰

2. æŒ‰ F5ï¼Œé€‰æ‹©"ğŸ› è°ƒè¯•GDN (å°æ•°æ®é›†)"

3. ç¨‹åºåœ¨ç¬¬125è¡Œæš‚åœ

4. åœ¨è°ƒè¯•æ§åˆ¶å°è¾“å…¥ï¼š
   >>> x.shape
   torch.Size([32, 38, 15])
   
   >>> x.device
   cuda:0
   
   >>> x.min(), x.max()
   (tensor(0.0234), tensor(0.9876))

5. æŒ‰ F10 å•æ­¥æ‰§è¡Œï¼ˆæ‰§è¡Œç¬¬125è¡Œï¼‰

6. å†æ¬¡åœ¨è°ƒè¯•æ§åˆ¶å°æŸ¥çœ‹ï¼š
   >>> out.shape
   torch.Size([32, 38])
   
   >>> out[0, :5]  # ç¬¬ä¸€ä¸ªæ ·æœ¬çš„å‰5ä¸ªé¢„æµ‹å€¼
   tensor([0.5234, 0.6123, 0.4567, 0.7890, 0.3456])

7. æŒ‰ F11 è¿›å…¥ model.forward() å‡½æ•°å†…éƒ¨ï¼ŒæŸ¥çœ‹è®¡ç®—è¿‡ç¨‹

8. æŒ‰ F5 ç»§ç»­è¿è¡Œåˆ°ä¸‹ä¸€ä¸ªæ–­ç‚¹
"""

print(è°ƒè¯•æµç¨‹)


"""
==========================================
ğŸ’¡ å®ç”¨æŠ€å·§
==========================================
"""

æŠ€å·§1_æ¡ä»¶æ–­ç‚¹ = """
å³é”®æ–­ç‚¹ â†’ "ç¼–è¾‘æ–­ç‚¹" â†’ è¾“å…¥ï¼š
    i_epoch == 10 and batch_idx == 0
è¿™æ ·åªåœ¨ç¬¬10ä¸ªepochçš„ç¬¬ä¸€ä¸ªbatchæš‚åœ
"""

æŠ€å·§2_æ—¥å¿—ç‚¹ = """
å³é”®æ–­ç‚¹ â†’ "æ·»åŠ æ—¥å¿—ç‚¹" â†’ è¾“å…¥ï¼š
    Epoch {i_epoch}, Loss: {loss.item():.6f}
ç¨‹åºä¼šæ‰“å°ä¿¡æ¯ä½†ä¸æš‚åœï¼Œéå¸¸é€‚åˆå¿«é€Ÿç›‘æ§
"""

æŠ€å·§3_å¿«é€ŸæŸ¥çœ‹å¼ é‡ = """
# åœ¨è°ƒè¯•æ§åˆ¶å°å®šä¹‰è¾…åŠ©å‡½æ•°ï¼š
def info(t):
    return f"shape={t.shape}, range=[{t.min():.3f}, {t.max():.3f}], mean={t.mean():.3f}"

# ç„¶åå¿«é€ŸæŸ¥çœ‹ï¼š
info(x)
info(out)
info(labels)
"""

æŠ€å·§4_æ¯”è¾ƒé¢„æµ‹å’ŒçœŸå€¼ = """
# åœ¨è°ƒè¯•æ§åˆ¶å°ï¼š
import matplotlib.pyplot as plt

# å¯è§†åŒ–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„é¢„æµ‹ vs çœŸå€¼
plt.figure(figsize=(10, 4))
plt.plot(out[0].cpu().detach().numpy(), label='é¢„æµ‹')
plt.plot(labels[0].cpu().detach().numpy(), label='çœŸå€¼')
plt.legend()
plt.savefig('debug_prediction.png')
"""


"""
==========================================
âš ï¸ å¸¸è§é—®é¢˜
==========================================
"""

é—®é¢˜1 = """
Q: å˜é‡é¢æ¿æ˜¾ç¤ºä¸å…¨ï¼Ÿ
A: ç‚¹å‡»å˜é‡åå·¦ä¾§çš„å±•å¼€ç®­å¤´ï¼Œæˆ–åœ¨è°ƒè¯•æ§åˆ¶å°ç›´æ¥è¾“å…¥å˜é‡åæŸ¥çœ‹
"""

é—®é¢˜2 = """
Q: è°ƒè¯•æ—¶ç¨‹åºå¾ˆæ…¢ï¼Ÿ
A: ä½¿ç”¨"ğŸ› è°ƒè¯•GDN (å°æ•°æ®é›†)"é…ç½®ï¼Œåªè®­ç»ƒ2ä¸ªepochï¼Œbatch=32
"""

é—®é¢˜3 = """
Q: æƒ³è·³è¿‡æŸäº›æ–­ç‚¹ï¼Ÿ
A: å³é”®æ–­ç‚¹é€‰æ‹©"ç¦ç”¨æ–­ç‚¹"ï¼Œæˆ–æŒ‰ä½Shift+F5åœæ­¢è°ƒè¯•
"""

é—®é¢˜4 = """
Q: å¦‚ä½•æŸ¥çœ‹å¼ é‡çš„å…·ä½“æ•°å€¼ï¼Ÿ
A: åœ¨è°ƒè¯•æ§åˆ¶å°è¾“å…¥ï¼š
   out[0].cpu().detach().numpy()  # è½¬ä¸ºnumpyæ•°ç»„
"""

é—®é¢˜5 = """
Q: å¦‚ä½•ä¿å­˜å½“å‰çŠ¶æ€ç”¨äºåç»­åˆ†æï¼Ÿ
A: åœ¨è°ƒè¯•æ§åˆ¶å°è¾“å…¥ï¼š
   torch.save({'x': x, 'out': out, 'labels': labels}, 'debug_state.pt')
   # ä¹‹åå¯ä»¥ç”¨ torch.load('debug_state.pt') åŠ è½½
"""


print("\nâœ… VS Code è°ƒè¯•å™¨ä½¿ç”¨æ£€æŸ¥æ¸…å•å‡†å¤‡å®Œæˆï¼")
print("ğŸ“ å¼€å§‹è°ƒè¯•æ—¶å¯ä»¥å‚è€ƒæ­¤æ–‡ä»¶")
print("\nğŸ¯ å¿«é€Ÿå¼€å§‹ä¸‰æ­¥ï¼š")
print("  1. åœ¨ train.py ç¬¬125è¡Œç‚¹å‡»æ·»åŠ æ–­ç‚¹")
print("  2. æŒ‰ F5 å¯åŠ¨è°ƒè¯•")
print("  3. åœ¨è°ƒè¯•æ§åˆ¶å°è¾“å…¥: x.shape, out.shape, loss.item()")
